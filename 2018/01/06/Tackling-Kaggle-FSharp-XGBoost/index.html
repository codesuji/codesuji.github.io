<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Tackling Kaggle with F# and XGBoost | codesuji</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Today’s topic will be to demonstrate tackling a Kaggle problem with XGBoost and F#.  Comparing Quora question intent offers a perfect opportunity to work with XGBoost, a common tool used in Kaggle com">
<meta name="keywords" content="F#,FSharp,Kaggle,Machine Learning,Analytics">
<meta property="og:type" content="article">
<meta property="og:title" content="Tackling Kaggle with F# and XGBoost">
<meta property="og:url" content="http://codesuji.com/2018/01/06/Tackling-Kaggle-FSharp-XGBoost/index.html">
<meta property="og:site_name" content="codesuji">
<meta property="og:description" content="Today’s topic will be to demonstrate tackling a Kaggle problem with XGBoost and F#.  Comparing Quora question intent offers a perfect opportunity to work with XGBoost, a common tool used in Kaggle com">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2018-01-05T02:53:07.683Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tackling Kaggle with F# and XGBoost">
<meta name="twitter:description" content="Today’s topic will be to demonstrate tackling a Kaggle problem with XGBoost and F#.  Comparing Quora question intent offers a perfect opportunity to work with XGBoost, a common tool used in Kaggle com">
  
    <link rel="alternate" href="/atom.xml" title="codesuji" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-89982547-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">codesuji</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://codesuji.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Tackling-Kaggle-FSharp-XGBoost" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/06/Tackling-Kaggle-FSharp-XGBoost/" class="article-date">
  <time datetime="2018-01-06T15:06:32.000Z" itemprop="datePublished">2018-01-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Tackling Kaggle with F# and XGBoost
    </h1>
  

 		<span class="post-count">Read Time: 16 minutes</span>
 	  </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Today’s topic will be to demonstrate tackling a <a href="https://www.kaggle.com/" target="_blank" rel="noopener">Kaggle</a> problem with <a href="https://github.com/dmlc/xgboost" target="_blank" rel="noopener">XGBoost</a> and <a href="http://fsharp.org/" target="_blank" rel="noopener">F#</a>.  <a href="https://www.kaggle.com/c/quora-question-pairs" target="_blank" rel="noopener">Comparing Quora question intent</a> offers a perfect opportunity to work with XGBoost, a common tool used in Kaggle competitions.  Luckily there is a .NET wrapper around the XGBoost library, <a href="https://github.com/PicNet/XGBoost.Net" target="_blank" rel="noopener">XGBoost.Net</a>.</p>
<a id="more"></a>
<p>Before going too far, let’s break down the data formats.  First, Kaggle provides a <code>train.csv</code> which is used for training models.  This contains question pairs and the ground truth regarding their duplicated-ness.  Second, <code>test.csv</code> is questions pairs with no ground truth.  This is used for generating the submission file to Kaggle.  Third, <code>submission.csv</code> are the results to submit to Kaggle for judging. <code>is_duplicate</code> represents a percentage likelihood of being a duplicate.  Below are example rows from each dataset.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">// train.csv</span><br><span class="line">&quot;id&quot;,&quot;qid1&quot;,&quot;qid2&quot;,&quot;question1&quot;,&quot;question2&quot;,&quot;is_duplicate&quot;                                                                </span><br><span class="line">&quot;0&quot;,&quot;1&quot;,&quot;2&quot;,&quot;What is the step by step guide to invest in share market in india?&quot;,&quot;What is the step by step guide to inves</span><br><span class="line">t in share market?&quot;,&quot;0&quot;                                                                                                  </span><br><span class="line">&quot;1&quot;,&quot;3&quot;,&quot;4&quot;,&quot;What is the story of Kohinoor (Koh-i-Noor) Diamond?&quot;,&quot;What would happen if the Indian government stole the K</span><br><span class="line">ohinoor (Koh-i-Noor) diamond back?&quot;,&quot;0&quot;                                                                                  </span><br><span class="line"></span><br><span class="line">// test.csv</span><br><span class="line">&quot;test_id&quot;,&quot;question1&quot;,&quot;question2&quot;</span><br><span class="line">0,&quot;How does the Surface Pro himself 4 compare with iPad Pro?&quot;,&quot;Why did Microsoft choose core m3 and not core i3 home Surface Pro 4?&quot;</span><br><span class="line">1,&quot;Should I have a hair transplant at age 24? How much would it cost?&quot;,&quot;How much cost does hair transplant require?&quot;</span><br><span class="line"></span><br><span class="line">// submission.csv</span><br><span class="line">test_id,is_duplicate</span><br><span class="line">0,0.425764</span><br><span class="line">1,0.212075</span><br></pre></td></tr></table></figure>
<p>Now that the data is out of the way, time to get started.  Using <a href="https://github.com/fsprojects/Paket" target="_blank" rel="noopener">Paket</a>, here is a sample paket.dependencies file.</p>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">source https:<span class="comment">//nuget.org/api/v2</span></span><br><span class="line"></span><br><span class="line">nuget FSharp.Data</span><br><span class="line">nuget PicNet.XGBoost</span><br></pre></td></tr></table></figure>
<p>Here is the boilerplate and initial variables.  Most of this is self-explanatory, although I want to call out a couple things specifically.  As expected, TypeProviders will be used to load the csv datasets.  When I get to the model training section, there will be hyperparameters.  This object will be managed by <code>ModelParameterType</code> and <code>ModelParameter</code>.  Feature extraction will use dataset-level metadata.  Since this is meant to be a simple example, the only metadata will be the average number of words in a question.  As shown above, the train and test files are slightly different formats.  Whatever method I use, I want to be able to run the same code against train and test.  <code>StandardRow</code> enables this by standardizing the input row format for transformation.</p>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">System.IO.Directory.SetCurrentDirectory(__SOURCE_DIRECTORY__)</span><br><span class="line">#r <span class="string">"../packages/FSharp.Data/lib/net40/FSharp.Data.dll"</span></span><br><span class="line">#r <span class="string">"../packages/PicNet.XGBoost/lib/net40/XGBoost.dll"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">open</span> System</span><br><span class="line"><span class="keyword">open</span> System.IO</span><br><span class="line"><span class="keyword">open</span> FSharp.Data</span><br><span class="line"><span class="keyword">open</span> XGBoost</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Percent of training dataset to use for training</span></span><br><span class="line"><span class="comment">/// Note: ValidationPct = 1. - TrainPct</span></span><br><span class="line"><span class="meta">[&lt;Literal&gt;]</span></span><br><span class="line"><span class="keyword">let</span> TrainPct = <span class="number">0.8</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/// Training filename</span></span><br><span class="line"><span class="meta">[&lt;Literal&gt;]</span></span><br><span class="line"><span class="keyword">let</span> TrainFilename = <span class="string">"../data/train.csv"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/// Kaggle test filename (used to generate submission)</span></span><br><span class="line"><span class="meta">[&lt;Literal&gt;]</span></span><br><span class="line"><span class="keyword">let</span> TestFilename = <span class="string">"../data/test.csv"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/// Kaggle submission filename</span></span><br><span class="line"><span class="meta">[&lt;Literal&gt;]</span></span><br><span class="line"><span class="keyword">let</span> SubmissionFilename = <span class="string">"../data/submission.csv"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/// Type of hyperparameter value</span></span><br><span class="line"><span class="class"><span class="keyword">type</span> <span class="title">ModelParameterType</span> </span>= | Int | Float32 </span><br><span class="line"><span class="comment">/// Model hyperparameter</span></span><br><span class="line"><span class="class"><span class="keyword">type</span> <span class="title">ModelParameter</span> </span>= &#123; Name: string; Type: ModelParameterType; Value: float &#125;</span><br><span class="line"><span class="comment">/// Dataset Metadata (Used for feature calculation)</span></span><br><span class="line"><span class="class"><span class="keyword">type</span> <span class="title">Metadata</span> </span>= &#123; AverageWordCount: float32 &#125;</span><br><span class="line"><span class="comment">// Standarized row</span></span><br><span class="line"><span class="class"><span class="keyword">type</span> <span class="title">StandardRow</span> </span>= &#123; QuestionId: int; Label: float32; Features: float32[] &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Training dataset</span></span><br><span class="line"><span class="class"><span class="keyword">type</span> <span class="title">TrainData</span> </span>= CsvProvider&lt;TrainFilename&gt;</span><br><span class="line"><span class="comment">/// Test/Submission dataset</span></span><br><span class="line"><span class="class"><span class="keyword">type</span> <span class="title">TestData</span> </span>= CsvProvider&lt;TestFilename&gt;</span><br></pre></td></tr></table></figure>
<p>To ensure proper model training, the provided train.csv will be broken into a train and validation set.  This method could be more advanced, but take the first x% for training and 100-x% for validation works well enough in this case. Since the train and test files are different, a conversion function is needed.</p>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Sample dataset into train and validation datasets</span></span><br><span class="line"><span class="keyword">let</span> sample (input:CsvProvider&lt;TrainFilename&gt;) trainPct = </span><br><span class="line">  <span class="keyword">let</span> trainRows = int (float (input.Rows |&gt; Seq.length) * trainPct) </span><br><span class="line">  <span class="keyword">let</span> trainData = input.Rows |&gt; Seq.take trainRows |&gt; Seq.toArray</span><br><span class="line">  <span class="keyword">let</span> validatationData = input.Rows |&gt; Seq.skip trainRows |&gt; Seq.toArray</span><br><span class="line">  (trainData, validatationData)</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Convert the test data format to train data format</span></span><br><span class="line"><span class="comment">/// Note: This is necessary because their train and test datasets differ slightly</span></span><br><span class="line"><span class="keyword">let</span> convertTestToTrainFormat (input:CsvProvider&lt;TestFilename&gt;.Row []) :(CsvProvider&lt;TrainFilename&gt;.Row []) =</span><br><span class="line">  input</span><br><span class="line">  |&gt; Array.map (<span class="keyword">fun</span> x -&gt; <span class="keyword">new</span> CsvProvider&lt;TrainFilename&gt;.Row(x.Test_id, <span class="number">0</span>, <span class="number">0</span>, x.Question1, x.Question2, <span class="keyword">false</span>))</span><br></pre></td></tr></table></figure>
<p>Here are the feature generating, and supporting, functions.  For pedagogical reasons the feature set is going to be overly simplistic.  This won’t result in a great prediction result, but proper feature creation can be involved.  More advanced feature extraction will be addressed in a later post.  For now, this will be enough to get some results, without losing the primary goal in a forest of feature extraction code.</p>
<p>Some features will/may need aggregate information about the dataset.  This is commonly used to for scaling or comparison for averages.  This will be stored in a dataset metadata object that all rows will have access to during row transformation and feature extraction.  The row-specific features are length and wordcount for the two questions being compared.  In addition, the difference in wordcount between the questions is considered.</p>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Number of words in sentence</span></span><br><span class="line"><span class="keyword">let</span> wordCount (s:string) = Array.length (s.Split([| ' ' |])) </span><br><span class="line"></span><br><span class="line"><span class="comment">/// Absolute value</span></span><br><span class="line"><span class="keyword">let</span> abs (x:int) = Math.Abs(x)</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Calculate dataset metadata for feature calculation</span></span><br><span class="line"><span class="keyword">let</span> metadata (input:CsvProvider&lt;TrainFilename&gt;.Row []) =</span><br><span class="line">  <span class="keyword">let</span> averageWordCount = </span><br><span class="line">    input</span><br><span class="line">    |&gt; Array.collect (<span class="keyword">fun</span> row -&gt; [|</span><br><span class="line">      Array.length (row.Question1.Split([| ' ' |])); </span><br><span class="line">      Array.length (row.Question2.Split([| ' ' |])) |])</span><br><span class="line">    |&gt; Array.sum</span><br><span class="line">    |&gt; (<span class="keyword">fun</span> total -&gt; float32 total / float32 (input.Length * <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">  &#123; Metadata.AverageWordCount = averageWordCount &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Calculate features for a row</span></span><br><span class="line"><span class="keyword">let</span> rowFeatures (metadata:Metadata) (input:CsvProvider&lt;TrainFilename&gt;.Row) =</span><br><span class="line">  [|</span><br><span class="line">    float32 input.Question1.Length;</span><br><span class="line">    float32 input.Question2.Length;</span><br><span class="line">    (wordCount &gt;&gt; float32) input.Question1;</span><br><span class="line">    (wordCount &gt;&gt; float32) input.Question2;</span><br><span class="line">    (abs &gt;&gt; float32) (wordCount input.Question1 - wordCount input.Question2);</span><br><span class="line">  |]</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Transform csv row into label + features</span></span><br><span class="line"><span class="keyword">let</span> transform (metadata:Metadata) (input:CsvProvider&lt;TrainFilename&gt;.Row []) =</span><br><span class="line">  input</span><br><span class="line">  |&gt; Array.map(<span class="keyword">fun</span> row -&gt; </span><br><span class="line">    &#123;</span><br><span class="line">      StandardRow.QuestionId = row.Id;</span><br><span class="line">      Label = <span class="keyword">if</span> row.Is_duplicate <span class="keyword">then</span> float32 <span class="number">1.</span> <span class="keyword">else</span> float32 <span class="number">0.</span>;</span><br><span class="line">      Features = rowFeatures metadata row</span><br><span class="line">    &#125;  </span><br><span class="line">  )  </span><br></pre></td></tr></table></figure>
<p>Now it is time to look at the XGBoost functionality.  Generating a model is as simple as creating a classifier, applying a hyperparameter set, and then running <code>.Fit</code> using the training data (features, and labels).  One small mention, as can be seen, the library uses <code>float32[]</code> for most of it’s numeric interations.</p>
<p>Once the model is trained, it can be applied using <code>PredictProba</code> against an array of features (that match the structure of the training data).  The result is an array of probabilities per class.  Since this is a binary classification, <code>[0.34, 0.66]</code> means there is a 34% chance the result is false, and 66% chance the result is true.  For the final submission, a percentage is desired, but for training, it is useful to know the binary true/false regarding duplicate question status.</p>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Given training data and hyperparameters, create an xgboost classification model</span></span><br><span class="line"><span class="keyword">let</span> buildXgClassModel (trainInput:float32[][]) (trainOutput:float32[]) (parameters:ModelParameter list) = </span><br><span class="line">    <span class="keyword">let</span> model = XGBClassifier()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// To handle xgboost types, I carry along the type with parameter values, </span></span><br><span class="line">    <span class="comment">// and cast accordingly when I set the values</span></span><br><span class="line">    parameters </span><br><span class="line">    |&gt; List.iter (<span class="keyword">fun</span> parameter -&gt; </span><br><span class="line">        <span class="keyword">match</span> parameter.Type <span class="keyword">with</span></span><br><span class="line">        | Int     -&gt; model.SetParameter(parameter.Name, (int parameter.Value))</span><br><span class="line">        | Float32 -&gt; model.SetParameter(parameter.Name, (float32 parameter.Value)))</span><br><span class="line"></span><br><span class="line">    model.Fit(trainInput, trainOutput)</span><br><span class="line">    model</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> predictionProbabilities (model:XGBClassifier) (inputs:float32[][]) =</span><br><span class="line">    <span class="comment">// Note, provides prob for each class (ex: 0=0.67, 1=0.33)</span></span><br><span class="line">    model.PredictProba(inputs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> predictionValues (model:XGBClassifier) (inputs:float32[][]) =</span><br><span class="line">    <span class="comment">// Note, provides prob for each class (ex: 0=0.67, 1=0.33)</span></span><br><span class="line">    <span class="comment">// Higher probability is the class that "wins"</span></span><br><span class="line">    predictionProbabilities model inputs</span><br><span class="line">    |&gt; Array.map (<span class="keyword">fun</span> x -&gt; <span class="keyword">if</span> x.[<span class="number">0</span>] &gt; x.[<span class="number">1</span>] <span class="keyword">then</span> <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>To faciliate debugging and improvement, a confusion matrix is very useful.  This, along with an overall accuracy reporting will assign in future developmental interations.</p>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Compares target vs. predicted values</span></span><br><span class="line"><span class="keyword">let</span> comparePredictions (target:float32[]) predicted = </span><br><span class="line">  (target, predicted)</span><br><span class="line">  ||&gt; Array.zip</span><br><span class="line">  |&gt; Array.map (<span class="keyword">fun</span> (t, p) -&gt; ((int t) - p) = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/// Create confusion matrix of results (represented as an array of arrays)</span></span><br><span class="line"><span class="comment">/// Result:</span></span><br><span class="line"><span class="comment">/// [ </span></span><br><span class="line"><span class="comment">///  T=1,P=1  T=1,P=0</span></span><br><span class="line"><span class="comment">///  T=0,P=1  T=0,P=0</span></span><br><span class="line"><span class="comment">/// ]</span></span><br><span class="line"><span class="keyword">let</span> createConfusionMatrix (target:int[]) (predict:int[]) =</span><br><span class="line">  <span class="keyword">let</span> combined = (target, predict) ||&gt; Array.zip</span><br><span class="line"></span><br><span class="line">  <span class="keyword">let</span> aggregateRow combined filter = </span><br><span class="line">    combined</span><br><span class="line">    |&gt; Array.filter (<span class="keyword">fun</span> (_,p) -&gt; p=filter)</span><br><span class="line">    |&gt; Array.map (<span class="keyword">fun</span> (t,p) -&gt; ((<span class="keyword">if</span> t=<span class="number">1</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>), (<span class="keyword">if</span> t=<span class="number">0</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>)))</span><br><span class="line">    |&gt; Array.fold (<span class="keyword">fun</span> (a,b) (x,y) -&gt; (a+x, b+y)) (<span class="number">0</span>,<span class="number">0</span>) </span><br><span class="line"></span><br><span class="line">  <span class="keyword">let</span> pTrue = aggregateRow combined <span class="number">1</span></span><br><span class="line">  <span class="keyword">let</span> pFalse = aggregateRow combined <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  [|</span><br><span class="line">    [| fst pTrue; snd pTrue |];</span><br><span class="line">    [| fst pFalse; snd pFalse |]</span><br><span class="line">  |]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/// Print confusion matrix</span></span><br><span class="line"><span class="keyword">let</span> printConfusionMatrix targetValues predictedValues =</span><br><span class="line">  createConfusionMatrix targetValues predictedValues </span><br><span class="line">  |&gt; (<span class="keyword">fun</span> m -&gt; </span><br><span class="line">    printfn <span class="string">"T\P  %6s %6s"</span> <span class="string">"T"</span> <span class="string">"F"</span></span><br><span class="line">    printfn <span class="string">"T    %6d %6d"</span> (m.[<span class="number">0</span>].[<span class="number">0</span>]) (m.[<span class="number">0</span>].[<span class="number">1</span>])</span><br><span class="line">    printfn <span class="string">"F    %6d %6d"</span> (m.[<span class="number">1</span>].[<span class="number">0</span>]) (m.[<span class="number">1</span>].[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/// Use a model to create predictions from input values, </span></span><br><span class="line"><span class="comment">/// then compare target output to predicted output </span></span><br><span class="line"><span class="keyword">let</span> evaluatePredictionResults model input targetOutput = </span><br><span class="line">  <span class="keyword">let</span> predictedValidationValues = predictionValues model input </span><br><span class="line">  <span class="keyword">let</span> predictedValidationMatches = comparePredictions targetOutput predictedValidationValues</span><br><span class="line">  <span class="keyword">let</span> pctValidationMatches = float (predictedValidationMatches |&gt; Array.filter id |&gt; Array.length) / float (predictedValidationMatches |&gt; Array.length)</span><br><span class="line"></span><br><span class="line">  printfn <span class="string">"Accuracy: %f"</span> pctValidationMatches</span><br><span class="line">  printConfusionMatrix (targetOutput |&gt; Array.map int) predictedValidationValues </span><br></pre></td></tr></table></figure>
<p>Since the submission file has specific criteria, there are some functions to create the submission file. This is primarily formatting the percents as Kaggle expects and then writing the dataset to a file.</p>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Convert probabilities per classification to a single probability</span></span><br><span class="line"><span class="comment">/// Note: if class 0 "wins", invert its percent, since the final result expects low percents to map to class 0.</span></span><br><span class="line"><span class="keyword">let</span> convertPredictionToProbability (probabilities: float32[]) = </span><br><span class="line">  <span class="keyword">if</span> probabilities.[<span class="number">0</span>] &gt; probabilities.[<span class="number">1</span>] </span><br><span class="line">  <span class="keyword">then</span> <span class="number">1.</span>f - probabilities.[<span class="number">0</span>] </span><br><span class="line">  <span class="keyword">else</span> probabilities.[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/// Combine question ids with prediction results</span></span><br><span class="line"><span class="keyword">let</span> formatSubmissionData (rows:StandardRow[]) (predictions:float32[][]) = </span><br><span class="line">  (rows, predictions)</span><br><span class="line">  ||&gt; Array.zip</span><br><span class="line">  |&gt; Array.map (<span class="keyword">fun</span> (input, prediction) -&gt;</span><br><span class="line">    <span class="keyword">let</span> questionId = input.QuestionId</span><br><span class="line">    <span class="keyword">let</span> probability = convertPredictionToProbability prediction</span><br><span class="line">    (questionId, probability))</span><br><span class="line"></span><br><span class="line"><span class="comment">// Write submission data to file</span></span><br><span class="line"><span class="keyword">let</span> writeSubmissionFile (submissionFilename:string) (submissionData: (int * float32)[]) =</span><br><span class="line">    <span class="keyword">let</span> fileStream = <span class="keyword">new</span> StreamWriter(submissionFilename)</span><br><span class="line">    fileStream.WriteLine(<span class="string">"test_id,is_duplicate"</span>)</span><br><span class="line">    submissionData </span><br><span class="line">    |&gt; Array.iter(<span class="keyword">fun</span> (id, probability) -&gt;</span><br><span class="line">        <span class="keyword">let</span> line = sprintf <span class="string">"%d,%f"</span> id probability</span><br><span class="line">        fileStream.WriteLine(line)) </span><br><span class="line">    fileStream.Flush()</span><br><span class="line">    fileStream.Close()</span><br></pre></td></tr></table></figure>
<p>Now that all the hard work is done, it is time to put it all together.  The first step is data preparation.  First, load the training data and split into train and validation sets.  Second, build dataset level metadata.  Third, run transformations (feature creation) against the datasets.  Fourth, structure the data for model training by generating the appropriate label and features arrays. </p>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Training data</span></span><br><span class="line"><span class="keyword">let</span> allData = TrainData.Load(TrainFilename)</span><br><span class="line"><span class="keyword">let</span> (trainData, validationData) = sample allData TrainPct</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> trainMetadata = metadata trainData </span><br><span class="line"><span class="keyword">let</span> transformedTrainData = transform trainMetadata trainData</span><br><span class="line"><span class="keyword">let</span> transformedValidationData = transform trainMetadata validationData</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> trainInput = transformedTrainData |&gt; Array.map (<span class="keyword">fun</span> row -&gt; row.Features)</span><br><span class="line"><span class="keyword">let</span> trainOutput = transformedTrainData |&gt; Array.map (<span class="keyword">fun</span> row -&gt; row.Label)</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> validationInput = transformedValidationData |&gt; Array.map (<span class="keyword">fun</span> row -&gt; row.Features)</span><br><span class="line"><span class="keyword">let</span> validationOutput = transformedValidationData |&gt; Array.map (<span class="keyword">fun</span> row -&gt; row.Label)</span><br></pre></td></tr></table></figure>
<p>Time to train the model.  XGBoost supports the below parameters.  The values shown are populated with some reasonable values for the dataset in question.  Out of scope for this post, but hyperparameter optimization should be leveraged here to find the best training model. In a later post I’ll discuss a simple method to approach this topic.  </p>
<p>Once trained, report on prediction capability against the original training set as well as the validation set (which the model hasn’t seen).  </p>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Model training parameters</span></span><br><span class="line"><span class="keyword">let</span> modelParameters =  [</span><br><span class="line">  &#123; Name = <span class="string">"max_depth"</span>;        Type = ModelParameterType.Int;     Value = <span class="number">10.</span> &#125;;</span><br><span class="line">  &#123; Name = <span class="string">"learning_rate"</span>;    Type = ModelParameterType.Float32; Value = <span class="number">0.76</span> &#125;;</span><br><span class="line">  &#123; Name = <span class="string">"gamma"</span>;            Type = ModelParameterType.Float32; Value = <span class="number">1.9</span> &#125;;</span><br><span class="line">  &#123; Name = <span class="string">"min_child_weight"</span>; Type = ModelParameterType.Int;     Value = <span class="number">5.</span> &#125;;</span><br><span class="line">  &#123; Name = <span class="string">"max_delta_step"</span>;   Type = ModelParameterType.Int;     Value = <span class="number">0.</span> &#125;;</span><br><span class="line">  &#123; Name = <span class="string">"subsample"</span>;        Type = ModelParameterType.Float32; Value = <span class="number">0.75</span> &#125;;</span><br><span class="line">  &#123; Name = <span class="string">"colsample"</span>;        Type = ModelParameterType.Float32; Value = <span class="number">0.75</span> &#125;;</span><br><span class="line">  &#123; Name = <span class="string">"reg_lambda"</span>;       Type = ModelParameterType.Float32; Value = <span class="number">4.</span> &#125;;</span><br><span class="line">  &#123; Name = <span class="string">"reg_alpha"</span>;        Type = ModelParameterType.Float32; Value = <span class="number">1.</span> &#125; ]</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Trained model</span></span><br><span class="line"><span class="keyword">let</span> finalModel = buildXgClassModel trainInput trainOutput modelParameters </span><br><span class="line"></span><br><span class="line"><span class="comment">// Predict train values</span></span><br><span class="line">evaluatePredictionResults finalModel trainInput trainOutput</span><br><span class="line"></span><br><span class="line"><span class="comment">// Validate Step</span></span><br><span class="line">evaluatePredictionResults finalModel validationInput validationOutput</span><br></pre></td></tr></table></figure>
<p>Here are the prediction results of train and test.  The prediction capability isn’t great, but the validation set holds up comparatively well.  At least overfitting isn’t a concern (for now).  This also shows how more and better features have plenty of room for improvement. </p>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt; evaluatePredictionResults finalModel trainInput trainOutput</span><br><span class="line">Accuracy: <span class="number">0.680396</span></span><br><span class="line">T\P       T      F</span><br><span class="line">T     <span class="number">53352</span>  <span class="number">36546</span></span><br><span class="line">F     <span class="number">66824</span> <span class="number">166710</span></span><br><span class="line"></span><br><span class="line">&gt; evaluatePredictionResults finalModel validationInput validationOutput</span><br><span class="line">Accuracy: <span class="number">0.651030</span></span><br><span class="line">T\P       T      F</span><br><span class="line">T     <span class="number">11625</span>  <span class="number">10755</span></span><br><span class="line">F     <span class="number">17462</span>  <span class="number">41016</span></span><br></pre></td></tr></table></figure>
<p>Now it is time to create the final predictions and submission file for Kaggle.  To do this, replicate the validate workflow, with a couple caveats.  First, the test dataset is formatted slightly differently.  Since this is data with no known classificaions, there is no class in the file.  So I need to load the test data, then run the convert so the test data matches the format of the training data.  Second, the submission file needs to be populated with a percent likelihood of the questions being duplicates (not with a straight classification).  Lastly, write the id along with the result to the submission file.</p>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> testData = TestData.Load(TestFilename).Rows |&gt; Seq.toArray</span><br><span class="line"><span class="keyword">let</span> transformedTestData = transform trainMetadata (convertTestToTrainFormat testData)</span><br><span class="line"><span class="keyword">let</span> testInput = transformedTestData |&gt; Array.map (<span class="keyword">fun</span> row -&gt; row.Features)</span><br><span class="line"><span class="keyword">let</span> testPredictions = predictionProbabilities finalModel testInput </span><br><span class="line"><span class="keyword">let</span> submissionData = formatSubmissionData transformedTestData testPredictions</span><br><span class="line">writeSubmissionFile SubmissionFilename submissionData</span><br></pre></td></tr></table></figure>
<p>All that is left to do is submit the file for judging.  Spolier alert, because this is an overly simplified model, it faired poorly.  Like I mentioned in the beginning, the current feature set isn’t good.  In addition, the hyper-parameters could benefit from some search of their own.  These are both topics I plan on discussing in future posts.  F# and .NET still have a couple more tricks up their sleeves to get these results even better.  Hopefully this has provided a bit of inspiration to try F# in your own projects, perhaps even a Kaggle.  Until next time.</p>

        <div class="related-posts-box">
        Related Posts:<ul class="related-posts"><li class="related-posts-item"><a class="related-posts-link" href="/2018/04/24/FSharp-and-Word-Stems/">F# and Word Stems</a></li><li class="related-posts-item"><a class="related-posts-link" href="/2017/01/20/F-and-Text-Analytics/">F# and Text Analytics</a></li><li class="related-posts-item"><a class="related-posts-link" href="/2017/08/27/K-Means-Clustering-with-F/">K-Means Clustering with F#</a></li></ul>        </div>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://codesuji.com/2018/01/06/Tackling-Kaggle-FSharp-XGBoost/" data-id="cjdxxxwbg000wjbm0wpbkbxt9" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Analytics/">Analytics</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/F/">F#</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/FSharp/">FSharp</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kaggle/">Kaggle</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/02/10/Coding-with-Color/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Coding with Color
        
      </div>
    </a>
  
  
    <a href="/2017/12/26/The-Power-of-the-Forward-Pipe/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">The Power of the Forward Pipe</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/NET-Core/" style="font-size: 13.75px;">.NET Core</a> <a href="/tags/Accord-NET/" style="font-size: 16.25px;">Accord.NET</a> <a href="/tags/Analytics/" style="font-size: 15px;">Analytics</a> <a href="/tags/Audio/" style="font-size: 10px;">Audio</a> <a href="/tags/Classification/" style="font-size: 11.25px;">Classification</a> <a href="/tags/Cognitive-Services/" style="font-size: 11.25px;">Cognitive Services</a> <a href="/tags/Compiler/" style="font-size: 13.75px;">Compiler</a> <a href="/tags/Computer-Vision/" style="font-size: 11.25px;">Computer Vision</a> <a href="/tags/DTW/" style="font-size: 11.25px;">DTW</a> <a href="/tags/Data/" style="font-size: 17.5px;">Data</a> <a href="/tags/Database/" style="font-size: 11.25px;">Database</a> <a href="/tags/Decision-Trees/" style="font-size: 11.25px;">Decision Trees</a> <a href="/tags/Deedle/" style="font-size: 10px;">Deedle</a> <a href="/tags/Delegate/" style="font-size: 10px;">Delegate</a> <a href="/tags/Detection/" style="font-size: 10px;">Detection</a> <a href="/tags/Dynamic-Time-Warping/" style="font-size: 11.25px;">Dynamic Time Warping</a> <a href="/tags/EEG/" style="font-size: 10px;">EEG</a> <a href="/tags/Edges/" style="font-size: 10px;">Edges</a> <a href="/tags/EmguCV/" style="font-size: 10px;">EmguCV</a> <a href="/tags/F/" style="font-size: 20px;">F#</a> <a href="/tags/FParsec/" style="font-size: 12.5px;">FParsec</a> <a href="/tags/FSAdvent/" style="font-size: 10px;">FSAdvent</a> <a href="/tags/FSharp/" style="font-size: 20px;">FSharp</a> <a href="/tags/Faces/" style="font-size: 11.25px;">Faces</a> <a href="/tags/Filters/" style="font-size: 10px;">Filters</a> <a href="/tags/Http/" style="font-size: 11.25px;">Http</a> <a href="/tags/Images/" style="font-size: 12.5px;">Images</a> <a href="/tags/Ionide/" style="font-size: 10px;">Ionide</a> <a href="/tags/Kaggle/" style="font-size: 12.5px;">Kaggle</a> <a href="/tags/Legos/" style="font-size: 11.25px;">Legos</a> <a href="/tags/Logging/" style="font-size: 10px;">Logging</a> <a href="/tags/MLNet/" style="font-size: 12.5px;">MLNet</a> <a href="/tags/MSIL/" style="font-size: 12.5px;">MSIL</a> <a href="/tags/Machine-Learning/" style="font-size: 18.75px;">Machine Learning</a> <a href="/tags/MathNet/" style="font-size: 10px;">MathNet</a> <a href="/tags/Mono/" style="font-size: 10px;">Mono</a> <a href="/tags/Morse-Code/" style="font-size: 10px;">Morse Code</a> <a href="/tags/OpenCV/" style="font-size: 10px;">OpenCV</a> <a href="/tags/Optimization/" style="font-size: 10px;">Optimization</a> <a href="/tags/Parsing/" style="font-size: 12.5px;">Parsing</a> <a href="/tags/Racket/" style="font-size: 10px;">Racket</a> <a href="/tags/Regression/" style="font-size: 10px;">Regression</a> <a href="/tags/Rekognition/" style="font-size: 10px;">Rekognition</a> <a href="/tags/Robotics/" style="font-size: 10px;">Robotics</a> <a href="/tags/Scoring/" style="font-size: 10px;">Scoring</a> <a href="/tags/Signals/" style="font-size: 11.25px;">Signals</a> <a href="/tags/Similarity/" style="font-size: 11.25px;">Similarity</a> <a href="/tags/Sound/" style="font-size: 10px;">Sound</a> <a href="/tags/Statistics/" style="font-size: 13.75px;">Statistics</a> <a href="/tags/Tail-calls/" style="font-size: 10px;">Tail calls</a> <a href="/tags/Text/" style="font-size: 12.5px;">Text</a> <a href="/tags/Translation/" style="font-size: 10px;">Translation</a> <a href="/tags/VS-Code/" style="font-size: 10px;">VS Code</a> <a href="/tags/Webapi/" style="font-size: 11.25px;">Webapi</a> <a href="/tags/admin/" style="font-size: 11.25px;">admin</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">February 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li></ul>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 codesuji.com<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>